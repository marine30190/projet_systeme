{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L6hc93Jxbxia",
        "J1z31uynWaSa",
        "Mtl44nHVLbDI",
        "ZNNsk-M39NGp",
        "XkWfu6KxUspa",
        "wRBs7htqueGw",
        "CMTS9RblVAn8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marine30190/projet_systeme/blob/main/projetSysteme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System project by Romain VICENS, Marine DALLO and Viktor ILIEV."
      ],
      "metadata": {
        "id": "ABJO_rKYvefi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***System project : HAI724I***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CmV12P3Rd9gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Lors des séquençages haut débit, beaucoup de données sont générées et pour pouvoir analyser toutes ces données, appelées \"BigData\", les bio informaticiens doivent créer des outils et des programmes puissants.\n",
        "Le type SAM signifit sequencis aligment mapping, c'est à dire que ce sont les données de l'alignement des reads séquencés grâce aux nouvelles techniques de séquençage.\n",
        "Le but de ce projet est de pouvoir trier et analyser un fichier de type .sam. "
      ],
      "metadata": {
        "id": "rKhStwcsehFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Script permission :**\n",
        "\n",
        "Start of the text with the permissions to code in Python:"
      ],
      "metadata": {
        "id": "1gMUYhTLvwAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !/usr/bin/python3\n",
        "#-*- coding : utf-8 -*-"
      ],
      "metadata": {
        "id": "zXIC-lL6v05E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Prompt authorisations :**\n",
        "This part concerns the authors and their contacts, the version of the programme as well as its creation date and the licence concerning the rights of copying and use."
      ],
      "metadata": {
        "id": "IQtfd2WaySHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"__authors__ = (\"Romain VICENS\", \"Marine DALLO\", \"Viktor ILIEV\")\n",
        "__contact__ = (\"romain.vicens@etu.umontpellier.fr\",\"marine.dallo@etu.umontpellier.fr\",\"viktor.iliev@etu.umontpellier.fr\")\n",
        "__version__ = \"0.0.1\"\n",
        "__date__ = \"05/12/2022\"\n",
        "__licence__ =\"This program is free software: you can redistribute it and/or modify\n",
        "        it under the terms of the GNU General Public License as published by\n",
        "        the Free Software Foundation, either version 3 of the License, or\n",
        "        (at your option) any later version.\n",
        "        This program is distributed in the hope that it will be useful,\n",
        "        but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "        MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
        "        GNU General Public License for more details.\n",
        "        You should have received a copy of the GNU General Public License\n",
        "        along with this program. If not, see <https://www.gnu.org/licenses/>.\"\"\""
      ],
      "metadata": {
        "id": "o2JnrHQswTNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Import of modules :**\n",
        "This import will allow you to run options like os, sys.argv, sam ..."
      ],
      "metadata": {
        "id": "j3N9VE_ByQkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, sam"
      ],
      "metadata": {
        "id": "jOKIPWVKKyO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Checking the file:**\n",
        "\n",
        "To be able to launch the program on the good type of file it is important to check the nature and the contents of the file which one wishes to analyze. To do this, we will check that the type of the file is not other than file, that is, that it is not a directory. Next, we will check the extension of the file, in this case the extension must be .sam, and we will display an error message if the file or the extension are not those required to run the program. If the file is not a .sam and is empty we stop the program to save time and memory. Then check that the file has content and we will give it a minimum number of 3 lines to say that it is not empty. The 3 lines are justified by the 2 lines of the file identifier and at least one line of read. If the file has less than 3 lines, we will display an error message to indicate that the file is empty."
      ],
      "metadata": {
        "id": "2UcBzlmtLAOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isdir(sys.argv[1]): #repertoire ou non \n",
        "  print(\"this is a directory\")\n",
        "  sys.exit(1)\n",
        "elif sys.argv[1].endswith('.sam'):\n",
        "  print(\"this the correct file\")\n",
        "else : \n",
        "  print(\"this is not a .sam file\")\n",
        "  print(\"please give me a unique .sam file as parameter\")\n",
        "  print(\"usage : python3\", sys.argv[0], \"tree/file_name.sam\")\n",
        "  sys.exit(1)\n",
        "        #veryfing if the file is empty\n",
        "if os.stat(sys.argv[1]).st_size < 3:\n",
        "  print(\"The file is empty\")\n",
        "else : \n",
        "  print(\"I have the data\")\n",
        " "
      ],
      "metadata": {
        "id": "HVgcbzBELPIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Open and read the .sam file:**\n",
        "\n",
        "This part of the program will open the file and read its contents in order to extract the lines of identification that begin with @, so that they are no longer available when the data is extracted for the analysis of the file. We will also initialise the variables that will be used for the counters used during the statistical readings."
      ],
      "metadata": {
        "id": "7ilgIhpRLPh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(sys.argv[1],'r') #ouvre le fichier mis en argument\n",
        "\n",
        "lines = f.readlines() #stock toutes les lignes du fichier\n",
        "readtotal=0 #initialiser la variable qui va compter les read totals à 0\n",
        "cpt_paireend_30=0 #initialisation de la variable qui va compter les paires end à 0\n",
        "cpt_single_30=0 #initialisation de la variable qui va compter les singles reads à 0\n",
        "GRsam=\"Good_Read_Of_Your_Sam.sam\" #initialisation de la variable qui va créer un nouveau fichier de sortie\n",
        "cpt_match = 0 #initialisation du compteur de match\n",
        "cigar=\"outpuTable_cigar.txt\" #création d'une variable pour la création d'un fichier de sortie\n",
        "final_cigar=\"Final_Cigar_table.txt\"\n",
        "txted=open(final_cigar,'w')\n",
        "\n",
        "#reserch headers ans stockage in variable for not to keep them for the rest of the programme\n",
        "for line in lines:\n",
        "\tif line[0].startswith('@'):\t\n",
        "\t\theader=line\n",
        "\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\tf.write(header)\n",
        "\t \t\t#importation des headers dans le nouveau fichier\t\t"
      ],
      "metadata": {
        "id": "Vb7bH7VPLTqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Checking the number of columns :**\n",
        "\n",
        "This part will allow you to check the number of columns. This will make it possible to check that the file, even if it is in the right format, has the right number of columns to be sure to have all the desired information. We have chosen to put the limits on the number of columns between 10 and 15. This is justified by the presence or absence of the last columns. They are optional and not present for all reads. If these criteria are not met, we stop the program."
      ],
      "metadata": {
        "id": "qfBqyM23LT0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\telse:\n",
        "\t\tline=line.split()\n",
        "\t\tif len(line) < 15 and len(line)>10:\n",
        "\t\t\tprint(\"this is not a .sam file\")\n",
        "\t\t\tprint(\"please give me a unique .sam file as parameter\")\n",
        "\t\t\tsys.exit(1)"
      ],
      "metadata": {
        "id": "4KRtNtOCYv60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Creating the dictionary:**\n",
        "\n",
        "Before creating the dictionary we will split the rows into columns, with a split(), to facilitate the extraction of the data that are present in the rows. This will allow us to create tables in the dictionary and thus extract the relevant information for analysis more easily. In addition to being able to extract more easily, it will allow us to query each column independently and to work with several sorting conditions. We also set a counter to read each extracted read to give the total number of reads."
      ],
      "metadata": {
        "id": "L6hc93Jxbxia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "else:\n",
        "\t\tdico = {'ID':line[0], 'FLAG':line[1], 'RNAME':line[2], 'POS':line[3], 'MAPQ':line[4], 'CIGAR':line[5], 'RNEXT':line[6], 'PNEXT':line[7], 'TLEN':line[8], 'SEQ':line[9], 'QUAL':line[10]} #création du dictionnaire\n",
        "\t\treadtotal+=1 #incrémentation de chaque read pour le compter tous les reads bon ou pas"
      ],
      "metadata": {
        "id": "B5lS5Ms-b0GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**OLD Sorting the pair ends with the Flags:**\n",
        "\n",
        "In the first version of the code we had thought of sorting the pair-ends according to the flag defined on the referring site of the SAM https://www.samformat.info/sam-format-flag, file and also sorting according to the quality by keeping only the QC > 30 to be very strict on the quality. But we opted for another solution described in the next block in case the Flags numbers would change according to the version. Here our counter counts the reads of each forward and reverse. We therefore increment by 0.5 to give the number of pairs as the final number."
      ],
      "metadata": {
        "id": "J1z31uynWaSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\t\t\t\"\"\"if ((dico['FLAG'] == '99' or dico['FLAG'] == '147') and int(dico['MAPQ'])>30): \n",
        "\t\t\t\tpaireend += 0.5\n",
        "\t\t\telif ((dico['FLAG'] == '83' or dico['FLAG'] == '163') and int(dico['MAPQ'])>30):\n",
        "\t\t\t\tpaireend +=  0.5\n",
        "\t\t\telse:\n",
        "\t\t\t\tpass\"\"\""
      ],
      "metadata": {
        "id": "p6sNu9LKLa4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Old sorting the pair-ends with the Flags :**\n",
        "\n",
        "In this new version, we switch the flag columns to binary to avoid errors when changing versions.\n",
        "To do this we will convert the Flag dico into 12 digit binary and then divide these 12 digits into a list to make it easier for the program to read the code.\n",
        "We choose to invert the reading of the binary code in the Flags column because Python reads from left to right, unlike us. This will make it easier to translate the binary code to find out the type of the read. \n",
        "We will also define a list of tuples with the meaning of each number to be able to profile the read. Example: if it is a well-mapped pair end."
      ],
      "metadata": {
        "id": "Mtl44nHVLbDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#convert the dico['FLAG'] into binary\n",
        "def convert_to_binary(dico):\n",
        "    #convert the dico['FLAG'] into binary with 12 digits\n",
        "    binary = bin(int(dico['FLAG'])).lstrip('-0b').zfill(12)\n",
        "    #split the binary into a list\n",
        "    binary = list(binary)\n",
        "    #reverse the list\n",
        "    binary = binary[::-1]\n",
        "    #define tuple list with the meaning of each digit\n",
        "    meaning = ('read paired', 'read mapped in proper pair', 'read unmapped', 'mate unmapped', 'read reverse strand', 'mate reverse strand', 'first in pair', 'second in pair', 'not primary alignment', 'read fails platform/vendor quality checks', 'read is PCR or optical duplicate', 'supplementary alignment')\"\"\""
      ],
      "metadata": {
        "id": "9dWVkAQJ9CWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Selecting flags for pair-ends reads:**\n",
        "\n",
        "In this part of the code, we will compare the binary digits in the flag column of each read with the list of corresponding flags. We will isolate the flags common to the pairs using the numbers: 110010100000, 110001010000,110010010000 and 110001100000 . These numbers are the equivalent of the flags that represent the reads in well-mapped end-pairs. We will then enter them into an output file and return them."
      ],
      "metadata": {
        "id": "ZNNsk-M39NGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\t\t\t\"\"\"if binary[0] == '1' and binary[1] == '1' and binary[2] == '0' and binary[3] == '0' and binary[4] == '1' and binary[5] == '0' and binary[6] == '1' and binary[7] == '0' and binary[8] == '0' and binary[9] == '0' and binary[10] == '0' and binary[11] == '0' and (int(dico['MAPQ'])>=30):\n",
        "\t\t\t\tcpt_paireend_30+=1\n",
        "\t\t\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\t\t\tf.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\tf.write(\"\\n\")\n",
        "\t\t\telif binary[0] == '1' and binary[1] == '1' and binary[2] == '0' and binary[3] == '0' and binary[4] == '0' and binary[5] == '1' and binary[6] == '0' and binary[7] == '1' and binary[8] == '0' and binary[9] == '0' and binary[10] == '0' and binary[11] == '0' and (int(dico['MAPQ'])>=30):\n",
        "\t\t\t\tcpt_paireend_30+=1\n",
        "\t\t\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\t\t\tf.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\tf.write(\"\\n\")\n",
        "\t\t\telif  binary[0] == '1' and binary[1] == '1' and binary[2] == '0' and binary[3] == '0' and binary[4] == '1' and binary[5] == '0' and binary[6] == '0' and binary[7] == '1' and binary[8] == '0' and binary[9] == '0' and binary[10] == '0' and binary[11] == '0' and (int(dico['MAPQ'])>=30):\n",
        "\t\t\t\tcpt_paireend_30+=1\n",
        "\t\t\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\t\t\tf.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\tf.write(\"\\n\")\n",
        "\t\t\telif binary[0] == '1' and binary[1] == '1' and binary[2] == '0' and binary[3] == '0' and binary[4] == '0' and binary[5] == '1' and binary[6] == '1' and binary[7] == '0' and binary[8] == '0' and binary[9] == '0' and binary[10] == '0' and binary[11] == '0' and (int(dico['MAPQ'])>=30):\n",
        "\t\t#compare each digit of the binary list with the flag list\n",
        "\t\t\t\tcpt_paireend_30+=1\n",
        "\t\t\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\t\t\tf.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\tf.write(\"\\n\")\n",
        "\t\t\telif binary[2]=='0' and binary[3]=='1' and (int(dico['MAPQ'])>=30):\n",
        "\t\t\t\tcpt_single_30 +=1\n",
        "\t\t\t\twith open(GRsam, 'a') as f:\n",
        "\t\t\t\t\tf.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\tf.write(\"\\n\")\n",
        "\t\t\telse :\n",
        "\t\t\t\tpass\"\"\""
      ],
      "metadata": {
        "id": "SBKKicGcUnJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**New selecting flags for pair-ends reads:**\n",
        "\n",
        "Improved version of the selection of flags for well-mapped and well-oriented end pairs and for well-mapped and well-oriented singles reads. The selection is still done with the previous binary codes and for the singles reads we have established by comparing with the flags of the badly mapped singles reads that the third binary digit should be 0 and therefore absent and the fourth present and therefore 1. \n",
        "This new version is more compact and allows a gain of line of code and thus of execution speed and memory."
      ],
      "metadata": {
        "id": "XkWfu6KxUspa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "          #convert the dico['FLAG'] into binary with 12 digits, isolate the results where binary is exclusively equals to : 110010100000, 110001010000,110010010000 and 110001100000\n",
        "            binary = bin(int(dico['FLAG'])).lstrip('-0b').zfill(12)\n",
        "            binary = '0b' + binary\n",
        "            if ((binary == '0b000001010011') or (binary == '0b000010100011') or (binary == '0b000001001011') or (binary == '0b000010010011')and (int(dico['MAPQ'])>=30)):\n",
        "               cpt_paireend_30+=1\n",
        "            #crate a sam file in the working diractory\n",
        "                with open(GRsam, 'a') as f:\n",
        "                    f.write(\"\\t\".join(dico.values()))\n",
        "                    f.write(\"\\n\")  \n",
        "            elif binary[2]=='0' and binary[3]=='1' and (int(dico['MAPQ'])>=30):\n",
        "                cpt_single_30 +=1 #incrémentation des singles reads\n",
        "\t\t\t\t        with open(GRsam, 'a') as f:\n",
        "\t\t\t\t\t        f.write(\"\\t\".join(dico.values()))\n",
        "\t\t\t\t\t        f.write(\"\\n\")\n",
        "            else:\n",
        "                pass"
      ],
      "metadata": {
        "id": "rI-12U4mhDWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**CIGAR Analysis :**\n",
        "\n",
        "We tryed to make a function called in the program after the reading of the .sam file. Supposément la fonction devait lire un fichier généré dans les selections de flag pour les lectures terminaisons-pairées. Cette fonction devait prendre la valeur avant chaque lettre présente dans le cigar, l'assigner à un dictionnaire par correspondance des lettres du cigar. Malheureusement nous n'avons pas réussi à isoler les nombres mais chaque chiffre. Ce problème rends la lecture du fichier final_cigar impossible."
      ],
      "metadata": {
        "id": "wRBs7htqueGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cigar=\"outpuTable_cigar.txt\"\n",
        "#function to create a table with the number behind each cigar letter\n",
        "def cigar_table():\n",
        "#open the cigar file and read the lines\n",
        "\tf = open(cigar,'r')\n",
        "\tlines = f.readlines()\n",
        "\tfor line in lines:\n",
        "\t\t#define a dictionary with the cigar and the number of occurence\n",
        "\t\tdico = {'M':0, 'I':0, 'D':0, 'N':0, 'S':0, 'H':0, 'P':0, '=':0, 'X':0}\n",
        "\t\t#if there is one of the cigar letter in the line, put the digits behind in the matching key in dico\n",
        "\t\tif 'M' in line:\n",
        "\t\t\tdico['M'] = int(line.split('M')[0])\n",
        "\t\tif 'I' in line:\n",
        "\t\t\tdico['I'] = int(line.split('I')[0])\n",
        "\t\tif 'D' in line:\n",
        "\t\t\tdico['D'] = int(line.split('D')[0])\n",
        "\t\tif 'N' in line:\n",
        "\t\t\tdico['N'] = int(line.split('N')[0])\n",
        "\t\tif 'S' in line:\n",
        "\t\t\tdico['S'] = int(line.split('S')[0])\n",
        "\t\tif 'H' in line:\n",
        "\t\t\tdico['H'] = int(line.split('H')[0])\n",
        "\t\tif 'P' in line:\n",
        "\t\t\tdico['P'] = int(line.split('P')[0])\n",
        "\t\tif '=' in line:\n",
        "\t\t\tdico['='] = int(line.split('=')[0])\n",
        "\t\tif 'X' in line:\n",
        "\t\t\tdico['X'] = int(line.split('X')[0])\n",
        "\t\t#write values in the dictionary in a txt file\n",
        "\t\t\n",
        "\t\twith open(final_cigar, 'a') as f:\n",
        "\t\t\tf.write(\"\\t\".join(str(x) for x in dico.values()))\n",
        "\t\t\tf.write(\"\\n\")"
      ],
      "metadata": {
        "id": "V1XIUK4ovQBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculs : \n",
        "\n",
        "Here we print the result of the counter for each condition."
      ],
      "metadata": {
        "id": "bU9s4JK_wKWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"le nombre de read total dans ce fichier est de : \", readtotal)\n",
        "\n",
        "print(\"le nombre de paire end bien mappé et bien orienté est de : \", cpt_paireend_30)\n",
        "\n",
        "print(\"le nombre de single read bien mappé est de : \",cpt_single_30)"
      ],
      "metadata": {
        "id": "JfPoBBsuxrce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if the file given in parameter is a .sam file\n",
        "if sys.argv[1].endswith('.sam'):\n",
        "    #open the file\n",
        "    with open(sys.argv[1]) as f:\n",
        "        #read the file\n",
        "        lines = f.readlines()\n",
        "        #veryfing if the file is empty\n",
        "        if os.stat(sys.argv[1]).st_size == 0:\n",
        "            print(\"The file is empty\")\n",
        "            sys.exit(1)\n",
        "        else:\n",
        "         #read the file\n",
        "            for line in f:\n",
        "                #split the line\n",
        "                line = line.split()\n",
        "                #check if the line is a header\n",
        "                if line[0].startswith('@'):\n",
        "                    #print the header\n",
        "                    print(line)\n",
        "                else:\n",
        "                    #store all the rows in a dictionary\n",
        "                    dico = {'QNAME':line[0], 'FLAG':line[1], 'RNAME':line[2], 'POS':line[3], 'MAPQ':line[4], 'CIGAR':line[5], 'RNEXT':line[6], 'PNEXT':line[7], 'TLEN':line[8], 'SEQ':line[9], 'QUAL':line[10]}\n",
        "                    #count the total number of reads\n",
        "                    total = total + 1\n",
        "                    #count the number of reads mapped to the reverse strand\n",
        "                    if dico['FLAG'] == '16':\n",
        "                        reverse = reverse + 1\n",
        "                    #count the number of reads mapped to the forward strand\n",
        "                    elif dico['FLAG'] == '0':\n",
        "                        forward = forward + 1\n",
        "                    #count the number of reads mapped to the reverse strand with a mapping quality equal or higher than 30\n",
        "                    if dico['FLAG'] == '16' and int(dico['MAPQ']) >= 30:\n",
        "                        reverse30 = reverse30 + 1\n",
        "                    #count the number of reads mapped to the forward strand with a mapping quality equal or higher than 30\n",
        "                    elif dico['FLAG'] == '0' and int(dico['MAPQ']) >= 30:\n",
        "                        forward30 = forward30 + 1\n",
        "                        #count the number of reads with proerly paired mates\n",
        "                    elif dico['FLAG'] == '99' or dico['FLAG'] == '147':\n",
        "                        proper = proper + 1\n",
        "                    #count the number of reads with a mapping quality equal or higher than 30\n",
        "                    elif int(dico['MAPQ']) >= 30:\n",
        "                        mapq30 = mapq30 + 1\n",
        "                        #count the number of reads totally aligned\n",
        "                    else :\n",
        "                        dico['CIGAR'] == '100M'\n",
        "                        aligned = aligned + 1\n",
        "    #print the results\n",
        "    print(\"Total number of reads: \", total)\n",
        "    print(\"Number of reads mapped to the reverse strand: \", reverse)\n",
        "    print(\"Number of reads mapped to the forward strand: \", forward)\n",
        "#    print(\"Number of reads mapped to the reverse strand with a mapping quality equal or higher than 30: \", reverse30)\n",
        "#    print(\"Number of reads mapped to the forward strand with a mapping quality equal or higher than 30: \", forward30)\n",
        "    print(\"Number of reads with proerly paired mates: \", proper)\n",
        "    print(\"Number of reads with a mapping quality equal or higher than 30: \", mapq30)\n",
        "    print(\"Number of reads totally aligned: \", aligned)\n",
        "else :\n",
        "    print(\"This is not a .sam file\")\n",
        "    print(\"Please give a unique .sam file as parameter\")\n",
        "    print('Usage: python3', sys.argv[0], 'tree/file_name.sam')\n",
        "    sys.exit(1)\n",
        "print(\"The program is finished\")"
      ],
      "metadata": {
        "id": "7d1eGZm-U_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**First draft of program:**\n",
        "A first draft of the program was done in the first week of the project. The selection parameters in the \"if\" conditions did not match the encoding of the .SAM flag provided, and no output file was generated. This code was therefore discarded. In the execution order it looked for the termination of the argument put in position after the call of the program in a bash terminal (i.e. by typing python3 program_name file_name_to_be_analyzed.termination, the termination was checked. If the file was a .sam we checked if it had content, the header was displayed and then the program was analyzed line by line redistributed in a dictionary corresponding to the columns of a sam file. Finally it displayed the counting results in the terminal.\n",
        "If the file was not a .sam file the program displayed how to use the program before stopping. \n"
      ],
      "metadata": {
        "id": "CMTS9RblVAn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By now we have learned to make python code object oriented, so we build a program with a main and functions. Here is the final program."
      ],
      "metadata": {
        "id": "5Z38ORugjhgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python3\n",
        "#-*- coding : utf-8 -*-\n",
        " \n",
        "\"\"\"__authors__ = (\"Romain VICENS\", \"Marine DALLO\", \"Viktor ILIEV\")\n",
        "__contact__ = (\"romain.vicens@etu.umontpellier.fr\",\"marine.dallo@etu.umontpellier.fr\",\"viktor.iliev@etu.umontpellier.fr\")\n",
        "__version__ = \"0.0.1\"\n",
        "__date__ = \"05/12/2022\"\n",
        "__licence__ =\"This program is free software: you can redistribute it and/or modify\n",
        "       it under the terms of the GNU General Public License as published by\n",
        "       the Free Software Foundation, either version 3 of the License, or\n",
        "       (at your option) any later version.\n",
        "       This program is distributed in the hope that it will be useful,\n",
        "       but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "       MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
        "       GNU General Public License for more details.\n",
        "       You should have received a copy of the GNU General Public License\n",
        "       along with this program. If not, see <https://www.gnu.org/licenses/>.\"\"\"\n",
        " \n",
        "#import of module :\n",
        "import os, sys, re, time"
      ],
      "metadata": {
        "id": "3ygEVuTgjZUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have the same header as the begining except for the modules : we import re for the exploration of the cigar and time for a \"fun\" addon if you fail to give a correct sam file."
      ],
      "metadata": {
        "id": "vAcLf4qJkH-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is the main for the whole program. We chose to detail the main at first so the reader (you) will know how the program execute and then how each function will be explained."
      ],
      "metadata": {
        "id": "WmFdbvhHnUEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "def main (argv):\n",
        "   with open(argv[1],'r') as newFile:\n",
        "       lines : list[Line] = GetListOfLines(newFile.readlines())\n",
        "       if isDirectory(argv[1]) == True:\n",
        "           boom()\n",
        "           sys.exit()\n",
        "       elif isExtentionValid(argv[1], \"sam\") == False:\n",
        "           boom()\n",
        "           sys.exit()\n",
        "       elif isFileValid(lines) == False:\n",
        "           sys.exit()\n",
        "       totalReads(lines)\n",
        "       print(\"What quality of mapping do you want?\" + \"\\n\"+ \"Answer with a number in range of 0 - 60 \")\n",
        "       while True:\n",
        "           quality = int(input())\n",
        "           if quality not in range(60):\n",
        "               print(\"Your desired quality is not in the range, please enter new value for quality (between 0 and 60) \")\n",
        "           else:\n",
        "               break\n",
        "       checkQuality(lines, quality)\n",
        "       print(\"Would you like to save a file with the mapped or unmapped reads?\" + \"\\n\" + \"Answer with: mapped/unmapped\")\n",
        "       x = input()\n",
        "       if x == \"mapped\" :\n",
        "           print(\"Do you want all mapped reads?\" + \"\\n\" + \"Answer with : yes/no \")\n",
        "           y = input()\n",
        "           if y == \"yes\":\n",
        "               result = mapped(checkQuality(lines, quality))\n",
        "               print(\"Would you like the cigar procentage of mapped reads?\"+ \"\\n\" + \"Answer with : yes/no \")\n",
        "               if input() == \"yes\":\n",
        "                   globalPercentCigars(result)\n",
        "           elif y == \"no\":\n",
        "               print(\"Do you want mapped reads with correct orientation or wrong orientation?\"+ \"\\n\" + \"Answer with : correct/wrong/both \" )\n",
        "               z = input()\n",
        "               if z == \"correct\":\n",
        "                   mappedRightOrientation(checkQuality(lines, quality))\n",
        "               elif z == \"wrong\":\n",
        "                   mappedWrongOrientation(checkQuality(lines, quality))\n",
        "               elif z == \"both\":\n",
        "                   mappedWrongOrientation(checkQuality(lines, quality))\n",
        "                   mappedRightOrientation(checkQuality(lines, quality))\n",
        "       elif x == \"unmapped\":\n",
        "           print(\"Do you want all unmapped reads?\"+ \"\\n\" + \"Answer with : yes/no \")\n",
        "           y = input()\n",
        "           if y == \"yes\":\n",
        "               unmapped(checkQuality(lines, quality))\n",
        "           elif y == \"no\":\n",
        "               print(\"Do you want unmapped reads where single read of the pair in unmapped or where the pair is unmapped?\" + \"\\n\" + \"Answer with : single/pair/both \")\n",
        "               z = input()\n",
        "               if z == \"single\":\n",
        "                   singleUnmapped(checkQuality(lines, quality))\n",
        "               elif z == \"pair\":\n",
        "                   doubleUnmapped(checkQuality(lines, quality))\n",
        "               elif z == \"both\":\n",
        "                   singleUnmapped(checkQuality(lines, quality))\n",
        "                   doubleUnmapped(checkQuality(lines, quality))\n",
        " \n",
        "main(sys.argv)\n"
      ],
      "metadata": {
        "id": "Ur0731lcn2CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first we call the functionn to open the sam file.\n",
        "We split the file as lines.\n",
        "We verify if the file is a sam file, if it has data in, if it has the intended number of columns. boom() is a fancy fonction causing to quit the program.\n",
        "If all those condition are gathered we ask the user what he wants to do, all his responses will activate/unactivate fonctions."
      ],
      "metadata": {
        "id": "P9yfPX-poHig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Clearing the screen :**\n",
        "Cleans the terminal."
      ],
      "metadata": {
        "id": "m0GUOVhM0u3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cls():\n",
        "   os.system('cls' if os.name=='nt' else 'clear')"
      ],
      "metadata": {
        "id": "XyvcQ2Jt0utD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Saving the header as global variable :**\n",
        "It will be used in the method where we extract a list of the lines in the file\n"
      ],
      "metadata": {
        "id": "0nuVKU9Q0oDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global header"
      ],
      "metadata": {
        "id": "-DrC6RZp0n6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Defining a class for the columns :**\n",
        "This function will allow to define a class defining the content of each line."
      ],
      "metadata": {
        "id": "yfjHLslIrSlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "### Defining a class for the columns ###\n",
        "#Cet fonction va permettre de définir les colonnes dans les quels les lignes du fichier sam seront découpés en colonne\n",
        "class Line:\n",
        "   def __init__(self, originalLine, ID, FLAG, RNAME, POS, MAPQ, CIGAR, RNEXT, PNEXT, TLEN, SEQ, QUAL):\n",
        "       self.originalLine = originalLine\n",
        "       self.ID = ID\n",
        "       self.FLAG = FLAG\n",
        "       self.RNAME = RNAME\n",
        "       self.POS = POS\n",
        "       self.MAPQ = MAPQ\n",
        "       self.CIGAR = CIGAR\n",
        "       self.RNEXT = RNEXT\n",
        "       self.PNEXT = PNEXT\n",
        "       self.TLEN = TLEN\n",
        "       self.SEQ = SEQ\n",
        "       self.QUAL = QUAL\n"
      ],
      "metadata": {
        "id": "S2QJyEcVrPiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Str Represent the instance of the originalLine class :**"
      ],
      "metadata": {
        "id": "VloksYQVsJ1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "   def str(self):\n",
        "       return self.originalLine\n"
      ],
      "metadata": {
        "id": "LAmkF6cssSCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Get list of lines using the class method :**\n",
        "This part of the program allows to save the 2 header lines that start with \"@\" in a list and then continue the loop.\n",
        "Then the current line is splitted into a list where we keep only the 11 firsts columns.\n",
        "This program returns the list of class line where each row is saved in a cell. "
      ],
      "metadata": {
        "id": "6GaN1eabtSjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get list of lines using the class method ###\n",
        "def GetListOfLines(lines) -> list[Line]:\n",
        "   global header\n",
        "   header = \"\"\n",
        "   list : list[Line] = []\n",
        "   for line in lines:\n",
        "       if line.startswith(\"@\"):\n",
        "           header += line\n",
        "           continue\n",
        "       spls = line.split()\n",
        "       myCurrentLine = Line(line, spls[0], spls[1], spls[2], spls[3], spls[4], spls[5], spls[6], spls[7], spls[8], spls[9], spls[10])\n",
        "       list.append(myCurrentLine)\n",
        "   return list\n"
      ],
      "metadata": {
        "id": "kHA7fCUbtXce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Checking if the sam file is good and creating dictionary if it is :**\n",
        "This function checks if the file is empty and if it contains between 10 and 15 columns. If the result is negative it means the given file cannot be exploited.The whole program shuts down. Here you can see the first iteration of another function (funny but unnecessary, if we had more time we would remplace  the for boucle by boom() ).\n",
        "\n",
        "--- Sadly the part where it verifies that it contains between 10 and 15 columns isn't well written and doesn't work properly."
      ],
      "metadata": {
        "id": "sxSxKhi7t2bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def isFileValid(sam_lines):\n",
        "   if len(sam_lines) == 0:\n",
        "       print(\"The file is empty\")\n",
        "       print(\"Please give me a valid .sam file as parameter\")\n",
        "       print(\"The script will shut down in 5 seconds\")\n",
        "       for i in reversed(range(6)):\n",
        "           print(i)\n",
        "           time.sleep(1)\n",
        "       cls()\n",
        "       print(\"BOOM\")\n",
        "       return False\n",
        "   for line in sam_lines:\n",
        "       if len(sam_lines) < 15 and len(sam_lines) > 10:\n",
        "           print(\"This is not a valid .sam file, it has more than 15 columns or less than 10 columns\")\n",
        "           print(\"Please give me a valid .sam file as parameter\")\n",
        "           print(\"The script will shut down in 5 seconds\")\n",
        "           for i in reversed(range(6)):\n",
        "               print(i)\n",
        "               time.sleep(1)\n",
        "           cls()\n",
        "           print(\"BOOM\")\n",
        "           return False #replacing sys.exit(1) because sys.exit is stopping the program\n",
        "   return True\n"
      ],
      "metadata": {
        "id": "0lwZIEIHuCUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Checking file's extention :** ###\n",
        "This function will check if the extension is a .sam file by splitting the argument where there is a \".\" then comparing what's after the dot with a variable storing \"sam\"."
      ],
      "metadata": {
        "id": "qG29CEkYumpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def isExtentionValid(file, extentiontype):\n",
        "   fileExtention = file.split(\".\")\n",
        "   if fileExtention[1] == extentiontype:\n",
        "       return True\n",
        "   else:\n",
        "       return False"
      ],
      "metadata": {
        "id": "D-w-xQZsul7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Convert flag into binary :**\n",
        "This function will convert the flags column into binary to facilitate the search for different versions.\n",
        "Here the binary is generated with \"0b\" at the begining, we strip it while covering the eventuality this is a negative number, and add 0 up to 12 times to get a 12 digits binary.\n",
        "This function transforms the flag into a list and reverse it to make it match the reading direction of python.\n",
        "\n",
        "Here we should check if the flag is not out of the range of 12digits (breakpoint) in case the sequencer has a memory saturation or if the sam has been modified."
      ],
      "metadata": {
        "id": "3ad8LNZEwGTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flagBinary(flag):\n",
        "   bFlag = bin(int(flag)).lstrip('-0b').zfill(12) #split the binary into a list   \n",
        "   binaryFlag = list(bFlag)\n",
        "   revbinaryFlag = binaryFlag[::-1] #reverse the list\n",
        "   return revbinaryFlag\n"
      ],
      "metadata": {
        "id": "aoYtAhIlwHd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Total reads in the sam file :**\n",
        "In this part we will define all the variables used in the rest of the program for all the counters.\n",
        "It takes out the header and continue to read all lines. If the read is mapped we add 1 to the counter and then continue to check the subtypes if it's correct or wrong orientation and add counter for them respectively. It does the same for unmapped reads and then prints all the the counters as summary of the whole file that was read."
      ],
      "metadata": {
        "id": "HHWHmATtxicz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def totalReads(sam_lines : list[Line]):\n",
        "   totalReads = 0\n",
        "   mapped = 0\n",
        "   mappedRightOrientaion = 0\n",
        "   mappedWrongOrientation = 0\n",
        "   unmapped = 0\n",
        "   singleUnmapped = 0\n",
        "   doubleUnmapped = 0\n",
        "\n",
        "   for currline in sam_lines:\n",
        "       line = currline.str()\n",
        "       if line.startswith(\"@\"):\n",
        "           continue\n",
        "       col_line = line.split()\n",
        "       flag = flagBinary(col_line[1])\n",
        "       totalReads += 1\n",
        "      \n",
        " \n",
        "       if (int(flag[1]) == 1):     #if true = mapped\n",
        "           mapped += 1\n",
        "           intFlag = [int(i) for i in flag]\n",
        "           if (sum(intFlag) == 4):     #if true = right orientation\n",
        "               mappedRightOrientaion += 1\n",
        "           else:   #else wrong orientation\n",
        "               mappedWrongOrientation += 1\n",
        "       else:   #else unmapped\n",
        "           unmapped += 1\n",
        "           if int(flag[2]) and int(flag[3]) == 1: #if true = double\n",
        "               doubleUnmapped += 1\n",
        "           else:   #else single\n",
        "               singleUnmapped += 1\n",
        "   print(\"Total reads : \" + str(totalReads) + \"\\n\" + \"Mapped reads : \" + str(mapped) + \" from which \" + str(mappedRightOrientaion) + \" are right orientation and \" + str(mappedWrongOrientation) + \" are wrong orientation\" + \"\\n\" + \"Unmapped reads : \" + str(unmapped) + \" from which \" + str(doubleUnmapped) + \" are with both reads are unmapped and \" + str(singleUnmapped) + \" in which one of the reads is unmapped\")\n",
        " \n"
      ],
      "metadata": {
        "id": "qFAR9vcUxhyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Analysing unmapped - unmapped in general not single or pair :**\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the unmapped read condition.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "Fyj3phF6zbJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Analysing unmapped - unmapped in general not single or pair ###\n",
        "#This part is dedicated to the mis-mapped read with the Flag reading. \n",
        "def unmapped(sam_line):\n",
        "   unmapped_count = 0\n",
        "   result = []\n",
        "   with open(\"only_unmapped.sam\", \"a+\") as unmapped_fasta, open(\"summary_unmapped.txt\",\"w\") as summary_file: # \"a+\" is mode for open - append and \"w\" - write\n",
        "       unmapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           if line.startswith(\"@\"): # skip header\n",
        "               continue\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "           if int(flag[2]) == 1:       #only unmapped\n",
        "               unmapped_count += 1\n",
        "               unmapped_fasta.write(str(line))\n",
        "               result.append(currline)\n",
        "       summary_file.write(\"Total unmapped reads: \" + str(unmapped_count) + \"\\n\")\n",
        "   print(\"The files are saved as only_unmapped_both_reads.sam and summary_both_reads_unmapped.txt\")\n",
        "   return result\n"
      ],
      "metadata": {
        "id": "Ffkj1We7zZ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Sub class of unmapped - where both reads in pair are unmapped :**\n",
        "\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the unmapped read condition and the pair of reads is unmapped.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "_oaPVn6tzZrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Sub class of unmapped - where both reads in pair are unmapped ###\n",
        "# ditto for badly mapped pair-ends\n",
        "def doubleUnmapped(sam_line):\n",
        "   doubleCount = 0\n",
        "   result = []\n",
        "   with open(\"only_unmapped_both_reads.sam\", \"a+\") as both_reads_unmapped_fasta, open(\"summary_both_reads_unmapped.txt\", \"w\") as summary_file_of_both_reads_unmapped:\n",
        "       both_reads_unmapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           if line.startswith(\"@\"):\n",
        "               continue\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "       if (int(flag[2]) == 1 and int(flag[3]) == 1):       #unmapped and mate unmapped\n",
        "           doubleCount += 1\n",
        "           both_reads_unmapped_fasta.write(str(line))\n",
        "           result.append(currline)\n",
        "       summary_file_of_both_reads_unmapped.write(\"Total unmapped reads where both reads are unmapped: \" + str(doubleCount)+ \"\\n\")\n",
        "   print(\"The files are saved as only_unmapped_both_reads.sam and summary_both_reads_unmapped.txt\")\n",
        "   return result\n"
      ],
      "metadata": {
        "id": "upd7A71-zos-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Sub class of unmapped - where one of the reads in pair is unmapped :**\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the unmapped read condition and one read of the pair is unmapped.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "CjIOreeKztiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Sub class of unmapped - where one of the reads in pair is unmapped ###\n",
        "#ditto for badly mapped singles reads\n",
        "def singleUnmapped(sam_line):\n",
        "   singleCount = 0\n",
        "   result = []\n",
        "   with open(\"only_unmapped_single_read.sam\", \"a+\") as single_read_unmapped_fasta, open(\"summary_single_read_unmapped.txt\", \"w\") as summary_file_of_single_read_unmapped:\n",
        "       single_read_unmapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           if line.startswith(\"@\"):\n",
        "               continue\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "           if (int(flag[2]) == 1) or (int(flag[3]) == 1):         #unmapped or mate unmapped\n",
        "               singleCount += 1\n",
        "               single_read_unmapped_fasta.write(str(line))\n",
        "               result.append(currline)\n",
        "       summary_file_of_single_read_unmapped.write(\"Total unmapped reads where both reads are unmapped: \" + str(singleCount)+ \"\\n\")\n",
        "   print(\"The files are saved as only_unmapped_single_read.sam and summary_single_read_unmapped.txt\")\n",
        "   return result\n",
        " \n"
      ],
      "metadata": {
        "id": "reoJmAtQzuiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Analysing mapped reads :**\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the mapped read condition.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "9hb53Obtzz4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Analysing mapped ###\n",
        "#ditto for well-mapped reads\n",
        "def mapped(sam_line) -> list[Line]:\n",
        "   mapped_count = 0\n",
        "   result = []\n",
        "   with open(\"only_mapped.sam\", \"a+\") as mapped_fasta, open(\"summary_mapped.txt\",\"w\") as summary_file_of_mapped_reads: # \"a+\" is mode for open - append and \"w\" - write\n",
        "       mapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "           if int(flag[1]) == 1:       #only unmapped\n",
        "               mapped_count += 1\n",
        "               mapped_fasta.write(str(line))\n",
        "               result.append(currline)\n",
        "       summary_file_of_mapped_reads.write(\"Total mapped reads: \" + str(mapped_count) + \"\\n\" )\n",
        "   print(\"The files are saved as only_mapped.sam and summary_mapped.txt\")\n",
        "   return result\n",
        " \n"
      ],
      "metadata": {
        "id": "RApibgPVzzuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysing mapped reads with correct orientation :**\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the mapped read condition and it's a correct orientation.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "3nmYTIMcz1f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Analysing mapped - right orientation ###\n",
        "def mappedRightOrientation(sam_line):\n",
        "   rightOrientation = 0\n",
        "   result = []\n",
        "   with open(\"only_mapped_right_orientation.sam\", \"a+\") as right_orientation_mapped_fasta, open(\"summary_right_orienatiton_mapped.txt\",\"w\") as summary_file_of_right_orientation_mapped_reads: # \"a+\" is mode for open - append and \"w\" - write\n",
        "       right_orientation_mapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           if line.startswith(\"@\"): # skip header\n",
        "               continue\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "           if int(flag[1]) == 1:           #only mapped\n",
        "               intFlag = list(map(int, flag)) #map function transforming every parameter in the list(flag) to int\n",
        "               if (sum(intFlag) == 4):       #only correct orientation mapped\n",
        "                   rightOrientation += 1\n",
        "                   right_orientation_mapped_fasta.write(str(line))\n",
        "                   result.append(currline)\n",
        "       summary_file_of_right_orientation_mapped_reads.write(\"Total correct orientation mapped reads: \" + str(rightOrientation) + \"\\n\")\n",
        "   print(\"The files are saved as only_mapped_right_orientation.sam and summary_right_orientation_mapped.txt\")\n",
        "   return result\n"
      ],
      "metadata": {
        "id": "3owfUpPBz1XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysing mapped reads with wrong orientation :**\n",
        "This function transforms the flag from the lines in binary and verifies if it contains the mapped read condition with wrong orientation.If it's true in adds 1 to the counter and writes it in export file.\n",
        "The function returns result which is a list of all reads that answered the condition."
      ],
      "metadata": {
        "id": "2UGgYUH3z5MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Analysing mapped - incorrect orientation ###\n",
        "def mappedWrongOrientation(sam_line):\n",
        "   wrongOrientation = 0\n",
        "   result = []\n",
        "   with open(\"only_mapped_wrong_orientation.sam\", \"a+\") as wrong_orientation_mapped_fasta, open(\"summary_wrong_orienatiton_mapped.txt\",\"w\") as summary_file_of_wrong_orientation_mapped_reads: # \"a+\" is mode for open - append and \"w\" - write\n",
        "       wrong_orientation_mapped_fasta.write(header)\n",
        "       for currline in sam_line:\n",
        "           line = currline.str()\n",
        "           if line.startswith(\"@\"): # skip header\n",
        "               continue\n",
        "           col_line = line.split()\n",
        "           flag = flagBinary(col_line[1])\n",
        " \n",
        "           if int(flag[1]) == 1:           #only mapped\n",
        "               intFlag = list(map(int, flag))\n",
        "               if (sum(intFlag) == 3) or (sum(intFlag) == 5):       #only incorrect orientation mapped\n",
        "                   wrongOrientation += 1\n",
        "                   wrong_orientation_mapped_fasta.write(str(line))\n",
        "                   result.append(currline)\n",
        "       summary_file_of_wrong_orientation_mapped_reads.write(\"Total wrong orientation mapped reads: \" + str(wrongOrientation) + \"\\n\")\n",
        "   print(\"The files are saved as only_mapped_wrong_orientation.sam and summary_wrong_orientation_mapped.txt\")\n",
        "   return result\n",
        " \n"
      ],
      "metadata": {
        "id": "elywQXwxz5EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Check the quality of the mapping :**\n",
        "Given a list of `Line` objects from a SAM file, this function verify the MAPQ observed in the lines. It then verifies if MAPQ is equal or superior to the second parameter from the function, if it is then it adds it to list and returns the list.\n",
        "\n",
        "--- With -> list[Line] we define that the return of the function is mandatory in type of list from class Line (We used it in some of the other functions but due to lack of time we couldn't specify it's type in all of them). This check could be useful if we don't want the functions the return other type than that whichs precised."
      ],
      "metadata": {
        "id": "d9mANuvqz9FK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Check the quality of mapping ###\n",
        "def checkQuality(lines : list[Line], mapQuality:int) -> list[Line]:\n",
        "   mylist : list[Line] = []\n",
        "   for line in lines:\n",
        "       if int(line.MAPQ) >= mapQuality:\n",
        "           mylist.append(line)\n",
        "   return mylist\n"
      ],
      "metadata": {
        "id": "O62NvoqFz88y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysing the file and getting the distribution of cigars in percentage :**\n",
        " Given a list of `Line` objects from a SAM file, this function counts the number\n",
        " of each type of cigar mutation observed in the lines. It then calculates the global distribution of these mutations as a percentage and returns the result."
      ],
      "metadata": {
        "id": "n_bQaIvv0RqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Analysing the file and getting the distribution of cigars in percentage ###\n",
        "def globalPercentCigars(lines):\n",
        "   # Create a dictionary to store the counts for each type of cigar mutation\n",
        "#we will create a dictionary to list the matches the indels the skipped regions ...\n",
        " \n",
        "   cigar_counts = {\n",
        "       \"M\": 0,  # alignment match\n",
        "       \"I\": 0,  # insertion\n",
        "       \"D\": 0,  # deletion\n",
        "       \"S\": 0,  # skipped region\n",
        "       \"H\": 0,  # soft clipping\n",
        "       \"N\": 0,  # hard clipping\n",
        "       \"P\": 0,  # padding\n",
        "       \"X\": 0,  # sequence mismatch\n",
        "       \"=\": 0,  # sequence match\n",
        "   }\n",
        " \n",
        "   # Loop through the lines and count the number of each type of cigar mutation\n",
        "   for line in lines:\n",
        "       # Skip the header lines\n",
        "       if line.originalLine.startswith(\"@\"):\n",
        "           continue\n",
        " \n",
        "       # Parse the cigar string from the line\n",
        "       cigar_string = line.CIGAR\n",
        " \n",
        "       # Count the number of each type of cigar mutation in the string\n",
        "       for c in cigar_string:\n",
        "           if c in cigar_counts:\n",
        "               cigar_counts[c] += 1\n",
        " \n",
        "   # Calculate the total number of cigar mutations\n",
        "   total_count = sum(cigar_counts.values())\n",
        " \n",
        "   # Calculate the global distribution of cigar mutations as a percentage\n",
        "   global_distribution = {\n",
        "       k: round(100 * v / total_count, 2) for k, v in cigar_counts.items()\n",
        "   }\n",
        " \n",
        "   # Write the global distribution to a file\n",
        "   with open(\"global_distribution_in_percentage.txt\", \"w\") as f:\n",
        "       for mutation, percentage in global_distribution.items():\n",
        "           f.write(f\"{mutation}: {percentage}\\n\")\n",
        " \n",
        "   return global_distribution\n"
      ],
      "metadata": {
        "id": "Zk_OOZnk0Rh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comments :** \n",
        "Sadly due to lack of time we couldn't comment all our functions properly and reduce the use of repeating arguments and in loops."
      ],
      "metadata": {
        "id": "qDS_FXiB0aIV"
      }
    }
  ]
}